{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFT712 Projet Fin de Session\n",
    "\n",
    "------------------------------\n",
    "MAHDI AIT LHAJ LOUTFI (aitm2302)  \n",
    "YOVAN TURCOTTE (tury1903)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données et analyse des résultats :\n",
    "Dans ce Notebook, on va analyse les resultas de l'entrainement. Dans le fond on va choisir le modele avec la meilleur performance, et le tester sur les donnees de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#-------for Pre-Processing----\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler)\n",
    "from src.DataProcesser.Processer import DataProcesser\n",
    "#------------------------------\n",
    "import src.Manager\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger les données :\n",
    "Si la cellule suivante marche, ca veut dire que l'extraction des données marche tres bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total dataset has 990 observations with dimentionality 192.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>margin1</th>\n",
       "      <th>margin2</th>\n",
       "      <th>margin3</th>\n",
       "      <th>margin4</th>\n",
       "      <th>margin5</th>\n",
       "      <th>margin6</th>\n",
       "      <th>margin7</th>\n",
       "      <th>margin8</th>\n",
       "      <th>margin9</th>\n",
       "      <th>margin10</th>\n",
       "      <th>...</th>\n",
       "      <th>texture55</th>\n",
       "      <th>texture56</th>\n",
       "      <th>texture57</th>\n",
       "      <th>texture58</th>\n",
       "      <th>texture59</th>\n",
       "      <th>texture60</th>\n",
       "      <th>texture61</th>\n",
       "      <th>texture62</th>\n",
       "      <th>texture63</th>\n",
       "      <th>texture64</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.027344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.035156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.022461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.068359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.002930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.019531</td>\n",
       "      <td>0.023438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.048828</td>\n",
       "      <td>0.009766</td>\n",
       "      <td>0.013672</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     margin1   margin2   margin3   margin4   margin5   margin6   margin7  \\\n",
       "id                                                                         \n",
       "1   0.007812  0.023438  0.023438  0.003906  0.011719  0.009766  0.027344   \n",
       "2   0.005859  0.000000  0.031250  0.015625  0.025391  0.001953  0.019531   \n",
       "3   0.005859  0.009766  0.019531  0.007812  0.003906  0.005859  0.068359   \n",
       "5   0.000000  0.003906  0.023438  0.005859  0.021484  0.019531  0.023438   \n",
       "6   0.005859  0.003906  0.048828  0.009766  0.013672  0.015625  0.005859   \n",
       "\n",
       "    margin8   margin9  margin10  ...  texture55  texture56  texture57  \\\n",
       "id                               ...                                    \n",
       "1       0.0  0.001953  0.033203  ...   0.007812   0.000000   0.002930   \n",
       "2       0.0  0.000000  0.007812  ...   0.000977   0.000000   0.000000   \n",
       "3       0.0  0.000000  0.044922  ...   0.154300   0.000000   0.005859   \n",
       "5       0.0  0.013672  0.017578  ...   0.000000   0.000977   0.000000   \n",
       "6       0.0  0.000000  0.005859  ...   0.096680   0.000000   0.021484   \n",
       "\n",
       "    texture58  texture59  texture60  texture61  texture62  texture63  \\\n",
       "id                                                                     \n",
       "1    0.002930   0.035156        0.0        0.0   0.004883   0.000000   \n",
       "2    0.000977   0.023438        0.0        0.0   0.000977   0.039062   \n",
       "3    0.000977   0.007812        0.0        0.0   0.000000   0.020508   \n",
       "5    0.000000   0.020508        0.0        0.0   0.017578   0.000000   \n",
       "6    0.000000   0.000000        0.0        0.0   0.000000   0.000000   \n",
       "\n",
       "    texture64  \n",
       "id             \n",
       "1    0.025391  \n",
       "2    0.022461  \n",
       "3    0.002930  \n",
       "5    0.047852  \n",
       "6    0.031250  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DP = DataProcesser(seed = 16082604)\n",
    "DP.importData(label_name = 'species')\n",
    "print(f\"The total dataset has {DP.df().shape[0]} observations with dimentionality {DP.df().shape[1]}.\")\n",
    "DP.df().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organisation et distribution des données :\n",
    "1- On va premierement diviser les données d'entrainement,test et validation\n",
    "\n",
    "2- Faire un Sanity Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train + Validation dataset created\n"
     ]
    }
   ],
   "source": [
    "DP.split_data(test_ratio = 0.1)\n",
    "print(\"Train + Validation dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Check Verified!\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check\n",
    "#Verifier que toutes les classes du test set figurent dans les train + validation sets\n",
    "Diff = set(DP.labels_Test()) - set(DP.labels_Train()) #should be empty set\n",
    "if(Diff == set()):\n",
    "    print(\"Sanity Check Verified!\")\n",
    "else:\n",
    "    print(\"Sanity Check Verification Failed!\")\n",
    "    raise ValueError(\"There are no training observations for the classes : \"+ str(Diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement de resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5042 different models.\n"
     ]
    }
   ],
   "source": [
    "with open('../results/results.json') as f:\n",
    "    results = json.load(f)\n",
    "print(f'There are {len(results)} different models.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-cc578c9384f3>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precision = np.float(results[key]['results']['Precision'])\n",
      "<ipython-input-80-cc578c9384f3>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  recall = np.float(results[key]['results']['Recall'])\n"
     ]
    }
   ],
   "source": [
    "#Calculating FScore\n",
    "for key in results:\n",
    "    precision = np.float(results[key]['results']['Precision'])\n",
    "    recall = np.float(results[key]['results']['Recall'])\n",
    "    if(recall == 0.0 or precision == 0.0):\n",
    "        results[key]['results']['FScore'] = '0.000'\n",
    "    else:\n",
    "        results[key]['results']['FScore'] = str(2.0 / (1.0 / precision + 1.0 / recall))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chercher le meilleur modele pour chaque classifieur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier types are: {'LogisticRegressionModel', 'KernelModel', 'GenerativeModel'}\n"
     ]
    }
   ],
   "source": [
    "# Unique Classifiers type\n",
    "classifiers = set(map(lambda x: results[x]['pipeline']['ClassificationParams']['classifier'],results))\n",
    "\n",
    "#Get results for each classifier\n",
    "classifierResults = {classifier:[] for classifier in classifiers}\n",
    "for result in results.values():\n",
    "    classifier = result['pipeline']['ClassificationParams']['classifier']\n",
    "    classifierResults[classifier].append(result)\n",
    "    \n",
    "print('The classifier types are:', classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each classifier type, sort by best results\n",
    "sortedClassifiersBestAccuracy = {classifier:sorted( classifierResults[classifier], \n",
    "                                                    key = lambda x: x['results']['Accuracy'],\n",
    "                                                    reverse = True )[0] for classifier in classifiers}\n",
    "sortedClassifiersBestRecall   = {classifier:sorted( classifierResults[classifier], \n",
    "                                                    key = lambda x: x['results']['Recall'],\n",
    "                                                    reverse = True )[0] for classifier in classifiers}\n",
    "sortedClassifiersBestPrecision= {classifier:sorted( classifierResults[classifier], \n",
    "                                                    key = lambda x: x['results']['Precision'],\n",
    "                                                    reverse = True )[0] for classifier in classifiers}\n",
    "sortedClassifiersBestFScore   = {classifier:sorted( classifierResults[classifier], \n",
    "                                                    key = lambda x: x['results']['FScore'],\n",
    "                                                    reverse = True )[0] for classifier in classifiers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprintBestResults(bestModels,metric):\n",
    "    \"\"\"\n",
    "    Method that will nicely display the results\n",
    "    \n",
    "    \n",
    "    bestModels: best model for each classifier type\n",
    "    metric: str of Metric to be used.\n",
    "    \"\"\"\n",
    "    classifiers = set(bestModels)\n",
    "    DataManagerParams    = {classifier:bestModels[classifier]['pipeline']['DataPreProcessingParams']['cases'] \n",
    "                                                                                     for classifier in classifiers}\n",
    "    ClassificationParams = {classifier:bestModels[classifier]['pipeline']['ClassificationParams'] \n",
    "                                                                                     for classifier in classifiers}\n",
    "    metricResults = {classifier:bestModels[classifier]['results'][metric] for classifier in classifiers} \n",
    "          \n",
    "    columns = ['PreProcessing1', 'PreProcessing2', 'Hyperparams', metric]\n",
    "    df = pd.DataFrame(np.full((len(classifiers), 4), np.nan), columns = columns, index = classifiers)\n",
    "    for classifier in sorted(metricResults,key = lambda x: metricResults[x], reverse = True):\n",
    "        out = f\"For {classifier}, the model with the best {metric} of {metricResults[classifier]}\\n\\thas hyperparameters: \"\n",
    "        hyperparams = ClassificationParams[classifier] .copy()\n",
    "        del hyperparams['classifier']\n",
    "        hyperparams = [f'{hp}={str(hyperparams[hp])[:5]}' for hp in hyperparams]\n",
    "        preprocessing = [preprocess['method'] for preprocess in DataManagerParams[classifier]]\n",
    "        \n",
    "        \n",
    "        df.loc[classifier] = np.array([preprocessing[0],preprocessing[1],hyperparams,metricResults[classifier] ],dtype=object)\n",
    "        df.sort_values(metric,axis=0, inplace=True, ascending = False)\n",
    "    \n",
    "    #Printing\n",
    "    print('RESULTS')\n",
    "    print(df.drop('Hyperparams',axis=1).head())\n",
    "    print('\\nHYPERPARAMS')\n",
    "    print(df['Hyperparams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "                         PreProcessing1 PreProcessing2 Accuracy\n",
      "KernelModel              StandardScaler  LDA            0.984  \n",
      "LogisticRegressionModel  Normalize       LDA            0.978  \n",
      "GenerativeModel          StandardScaler  LDA            0.811  \n",
      "\n",
      "HYPERPARAMS\n",
      "KernelModel                [alpha=1e-09, kernel=rbf, gamma=0.002]                        \n",
      "LogisticRegressionModel    [solver=libli, random_state=0, penalty=l2, tol=0.000, C=78.47]\n",
      "GenerativeModel            []                                                            \n",
      "Name: Hyperparams, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pprintBestResults(sortedClassifiersBestAccuracy, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "                         PreProcessing1 PreProcessing2 Precision\n",
      "KernelModel              Normalize       LDA            0.986   \n",
      "LogisticRegressionModel  Normalize       LDA            0.979   \n",
      "GenerativeModel          StandardScaler  LDA            0.893   \n",
      "\n",
      "HYPERPARAMS\n",
      "KernelModel                [alpha=0.022, kernel=rbf, gamma=0.067]                        \n",
      "LogisticRegressionModel    [solver=libli, random_state=0, penalty=l2, tol=0.000, C=78.47]\n",
      "GenerativeModel            []                                                            \n",
      "Name: Hyperparams, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pprintBestResults(sortedClassifiersBestPrecision, 'Precision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "                         PreProcessing1 PreProcessing2 Recall\n",
      "KernelModel              Normalize       LDA            0.984\n",
      "LogisticRegressionModel  Normalize       LDA            0.977\n",
      "GenerativeModel          StandardScaler  LDA            0.779\n",
      "\n",
      "HYPERPARAMS\n",
      "KernelModel                [alpha=0.000, kernel=rbf, gamma=0.007]                        \n",
      "LogisticRegressionModel    [solver=libli, random_state=0, penalty=l2, tol=0.000, C=78.47]\n",
      "GenerativeModel            []                                                            \n",
      "Name: Hyperparams, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pprintBestResults(sortedClassifiersBestRecall, 'Recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS\n",
      "                         PreProcessing1 PreProcessing2 FScore\n",
      "KernelModel              Normalize       LDA            0.984\n",
      "LogisticRegressionModel  Normalize       LDA            0.977\n",
      "GenerativeModel          StandardScaler  LDA            0.832\n",
      "\n",
      "HYPERPARAMS\n",
      "KernelModel                [alpha=0.000, kernel=rbf, gamma=0.007]                        \n",
      "LogisticRegressionModel    [solver=libli, random_state=0, penalty=l2, tol=0.000, C=78.47]\n",
      "GenerativeModel            []                                                            \n",
      "Name: Hyperparams, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pprintBestResults(sortedClassifiersBestFScore, 'FScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle finale choisie :\n",
    "Classifier: SVM  \n",
    "Hyperparameters:  \n",
    "C=1.623,\n",
    "kernel=linear,\n",
    "degree=2,\n",
    "gamma=1e-09  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pipeline': {'DataPreProcessingParams': {'seed': 16082604,\n",
       "   'cases': [{'method': 'Normalize', 'hyperparams': {}},\n",
       "    {'method': 'LDA', 'hyperparams': {'n_components': 100}}]},\n",
       "  'ClassificationParams': {'classifier': 'KernelModel',\n",
       "   'alpha': 0.00024255310558892541,\n",
       "   'kernel': 'rbf',\n",
       "   'gamma': 0.0071349432492320355},\n",
       "  'StatisticsParams': ['Accuracy', 'Precision', 'Recall']},\n",
       " 'results': {'Accuracy': '0.984',\n",
       "  'Precision': '0.985',\n",
       "  'Recall': '0.984',\n",
       "  'FScore': '0.984'}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedClassifiersBestFScore['KernelModel']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results sur le Test Set\n",
    "For the best F-Score result of each classifier type, we will be running on the test set and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Accuracy  Precision  Recall  FScore\n",
      "LogisticRegressionModel  0.996     0.996      0.998   0.996 \n",
      "KernelModel              0.992     0.986      0.985   0.985 \n",
      "GenerativeModel          0.875     0.897      0.890   0.893 \n"
     ]
    }
   ],
   "source": [
    "testSetResultsClassifiers = {}\n",
    "for classifier in classifiers:\n",
    "    testSetResults = src.Manager.runTestSet(**sortedClassifiersBestFScore[classifier]['pipeline'])\n",
    "    precision = float(testSetResults['metrics']['Precision'])\n",
    "    recall = float(testSetResults['metrics']['Recall'])\n",
    "    if(recall == 0.0 or precision == 0.0):\n",
    "        testSetResults['metrics']['FScore'] = 0.0\n",
    "    else:\n",
    "        testSetResults['metrics']['FScore'] = str(2.0 / (1.0 / precision + 1.0 / recall))[:5]\n",
    "    testSetResultsClassifiers[classifier] = testSetResults\n",
    "\n",
    "#Printing sorted results\n",
    "resultsTestSet = pd.DataFrame(np.zeros((3, 4)), columns = ['Accuracy','Precision','Recall','FScore'],index = classifiers)\n",
    "for classifier in sorted(testSetResultsClassifiers, key = lambda x:testSetResultsClassifiers[x]['metrics']['FScore'],reverse = True): \n",
    "    for metric in testSetResultsClassifiers[classifier]['metrics']:\n",
    "        resultsTestSet.loc[classifier][metric] = testSetResultsClassifiers[classifier]['metrics'][metric]\n",
    "print(resultsTestSet.sort_values('FScore',axis=0,ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprising! The Logistic Regression has a better FScore than SVM, which was our previous winner. This result is meaning less as the chosen model has to stem from the cross-validation results but it is still interesting. All being said, the 0.001 difference between the two models is statistically insignificant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix with SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating Confusion matrix\n",
    "testSetResults = src.Manager.runTestSet(**sortedClassifiersBestFScore['KernelModel']['pipeline'])\n",
    "predictions = testSetResults['predictions']\n",
    "truths = testSetResults['truths']\n",
    "sns.heatmap(confusion_matrix(truths,predictions))\n",
    "plt.xlabel('Predictions')\n",
    "plt.ylabel('Truths')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a very distinct straight diagonal, indicating we have good results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average results from preprocessing combination\n",
    "\n",
    "Our team is curious to see if preprocessing differently changed anything in the performance. We will verify below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprintPreprocessing(cmds):\n",
    "    return \"&\".join([cmd['method'] for cmd in cmds])\n",
    "preprocessCombinations = set(map(lambda x: pprintPreprocessing(results[x]['pipeline']['DataPreProcessingParams']['cases']), results))\n",
    "\n",
    "#Attach all results to their preprocessing combination\n",
    "preprocess = {combination:[] for combination in preprocessCombinations}\n",
    "for trial in results:\n",
    "    preprocess[pprintPreprocessing(results[trial]['pipeline']['DataPreProcessingParams']['cases'])].append(results[trial]['results'])\n",
    "    \n",
    "#Calculate average of metrics for every preprocess combination\n",
    "preprocessAvg = {}\n",
    "for combination in preprocessCombinations:\n",
    "    avgDict = {}\n",
    "    for metric in preprocess[combination][0].keys():\n",
    "        avgDict[metric] = sum(float(d[metric]) for d in preprocess[combination]) / len(preprocess[combination])\n",
    "    preprocessAvg[combination] = avgDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortPreProcessingByMetric(metric):\n",
    "    preprocessingSorted = sorted(preprocessAvg, key = lambda x: preprocessAvg[x][metric], reverse = True)\n",
    "    out = pd.DataFrame([],columns = [metric], index = preprocessingSorted)\n",
    "    for combination in preprocessingSorted:\n",
    "        out.loc[combination] = preprocessAvg[combination][metric]\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  Accuracy\n",
      "StandardScaler&LDA                0.818932\n",
      "StandardScaler&FeatureExtraction  0.760677\n",
      "Normalize&LDA                     0.748855\n",
      "Normalize&FeatureExtraction       0.679332\n"
     ]
    }
   ],
   "source": [
    "sortPreProcessingByMetric('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Precision\n",
      "StandardScaler&LDA                0.83118 \n",
      "StandardScaler&FeatureExtraction  0.766371\n",
      "Normalize&LDA                     0.755362\n",
      "Normalize&FeatureExtraction       0.68694 \n"
     ]
    }
   ],
   "source": [
    "sortPreProcessingByMetric('Precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Recall\n",
      "StandardScaler&LDA                0.805459\n",
      "StandardScaler&FeatureExtraction  0.744719\n",
      "Normalize&LDA                     0.733687\n",
      "Normalize&FeatureExtraction       0.661848\n"
     ]
    }
   ],
   "source": [
    "sortPreProcessingByMetric('Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    FScore\n",
      "StandardScaler&LDA                0.817264\n",
      "StandardScaler&FeatureExtraction  0.754444\n",
      "Normalize&LDA                     0.743331\n",
      "Normalize&FeatureExtraction       0.673043\n"
     ]
    }
   ],
   "source": [
    "sortPreProcessingByMetric('FScore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The StandardScaler & PCA (with num_components = 100) seems to be the best combination of preprocessing out of the 4 combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
